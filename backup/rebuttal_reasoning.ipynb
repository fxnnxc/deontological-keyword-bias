{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data1 = pd.read_csv('trainging_free_reasoning_exp_6_1_debising.csv')\n",
    "data2 = pd.read_csv('trainging_free_reasoning_exp_6_2_debising.csv')\n",
    "\n",
    "model_name_conversion = {\n",
    "    'openai--gpt-4o-mini': 'GPT-4o-mini',\n",
    "    'llama3_1_instruct--70b': 'Llama-3.1-70B-Instruct',\n",
    "    'llama3_1--8b': 'Llama-3.1-8B',\n",
    "    'gemma2--9b': 'Gemma-9B',\n",
    "    'qwen2--7b': 'Qwen-7B',\n",
    "    'exaone--8b': 'ExaOne-8B',\n",
    "    'type': 'type',\n",
    "    'reasoning': 'reasoning'\n",
    "}\n",
    "\n",
    "data1.columns = data1.columns.map(model_name_conversion)\n",
    "data2.columns = data2.columns.map(model_name_conversion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| reasoning         |   GPT-4o-mini |   Llama-3.1-70B-Instruct |   Llama-3.1-8B |   Gemma-9B |   Qwen-7B |\n",
      "|:------------------|--------------:|-------------------------:|---------------:|-----------:|----------:|\n",
      "| reasoning         |          0.69 |                     0.88 |           0.87 |       0.96 |      0.95 |\n",
      "| logical_reasoning |          0.97 |                     0.55 |           0.48 |       0.43 |      0.57 |\n",
      "| moral_reasoning   |          0.98 |                     0.6  |           0.84 |       0.96 |      0.79 |\n",
      "| third_person      |          0.99 |                     0.91 |           0.98 |       0.94 |      0.91 |\n",
      "---------\n",
      "| reasoning         |   GPT-4o-mini |   Llama-3.1-70B-Instruct |   Llama-3.1-8B |   Gemma-9B |   Qwen-7B |\n",
      "|:------------------|--------------:|-------------------------:|---------------:|-----------:|----------:|\n",
      "| reasoning         |          0.39 |                     0.56 |           0.8  |       0.9  |      0.76 |\n",
      "| logical_reasoning |          0.83 |                     0.13 |           0.1  |       0.32 |      0.26 |\n",
      "| moral_reasoning   |          0.89 |                     0.31 |           0.48 |       0.83 |      0.51 |\n",
      "| third_person      |          0.96 |                     0.86 |           0.54 |       0.89 |      0.88 |\n"
     ]
    }
   ],
   "source": [
    "temp = data1[data1['type'] == 'strong']\n",
    "temp2 = data2[data2['type'] == 'strong']\n",
    "temp =temp[['reasoning', 'GPT-4o-mini', 'Llama-3.1-70B-Instruct', 'Llama-3.1-8B', 'Gemma-9B', 'Qwen-7B']]\n",
    "temp2 = temp2[['reasoning', 'GPT-4o-mini', 'Llama-3.1-70B-Instruct', 'Llama-3.1-8B', 'Gemma-9B', 'Qwen-7B']]\n",
    "print(temp.to_markdown(index=False))\n",
    "print(\"---------\")\n",
    "print(temp2.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
